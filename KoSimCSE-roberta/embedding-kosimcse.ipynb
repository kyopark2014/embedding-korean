{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88930447-bd49-4d58-9ec2-c116ad73cf6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Referecne: [Korean Embedding 모델을 SageMaker 배포 및 추론](https://github.com/gonsoomoon-ml/Kor-LLM-On-SageMaker/blob/main/1-Lab01-Deploy-LLM/4.Kor-Embedding-Model.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37853a05-f167-4e62-b821-0fec0e3cebef",
   "metadata": {},
   "source": [
    "## HF Hub로 부터 모델 및 토큰 나이저 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e59554d-8495-4f12-bc39-16504bae0e18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m129.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.2.0 (from torch)\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.17.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchvision-0.17.0 triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c60eeb85-6435-4bed-8e87-5d46f959945c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers[torch]\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (3.12.4)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers[torch])\n",
      "  Using cached huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers[torch])\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers[torch])\n",
      "  Using cached safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers[torch]) (2.2.0)\n",
      "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
      "  Downloading accelerate-0.27.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.12.0,>=1.11->transformers[torch]) (12.3.101)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.11->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.11->transformers[torch]) (1.3.0)\n",
      "Downloading accelerate-0.27.0-py3-none-any.whl (279 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.7/279.7 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "Using cached safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers, accelerate\n",
      "Successfully installed accelerate-0.27.0 huggingface-hub-0.20.3 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.37.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "477b3741-3945-428f-9da9-f93d70085bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4507467734c44c28ca84f3bd67b48cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/744 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5282c81e1d6b4b2290c03364512e65ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85d13cbe2a64de0a07d4a0f4989a287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0f7aae77254447b1ef2e5717f6b320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3f5a1d2837405fb11217844ae2bf3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b234b51ee52a4e4a91de3d41e3c6abdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "model = AutoModel.from_pretrained('BM-K/KoSimCSE-roberta')\n",
    "tokenizer = AutoTokenizer.from_pretrained('BM-K/KoSimCSE-roberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb4ccf4-3172-4d5d-b4d7-ca220b65fc19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample : \n",
      " 이번 주 일요일에 분당 이마트 점은 문을 여나요\n",
      "embeding size:  768\n",
      "embeding content from 0 to 10 out of 768: \n",
      " tensor([-0.2569, -0.1982,  0.8970, -1.7043, -0.1197,  0.2872,  0.3933, -0.4806,\n",
      "        -0.1716, -0.6642], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample = \"이번 주 일요일에 분당 이마트 점은 문을 여나요\"\n",
    "\n",
    "inputs = tokenizer(sample, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "embeddings, _ = model(**inputs, return_dict=False)\n",
    "\n",
    "emb_len = len(embeddings[0][0])\n",
    "print(\"sample : \\n\", sample)\n",
    "print(\"embeding size: \", emb_len)\n",
    "print(f\"embeding content from 0 to 10 out of {emb_len}: \\n\", embeddings[0][0][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cef42f-3e19-4600-a6c4-62a1ff643eed",
   "metadata": {},
   "source": [
    "## 추론 테스트 및 문장 유사도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08a9977b-bf53-4715-a099-f4ec4fd43692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_embedding_score(tokenizer, model, sentences):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    embeddings, _ = model(**inputs, return_dict=False)\n",
    "\n",
    "    score01 = cal_score(embeddings[0][0], embeddings[1][0])\n",
    "    score02 = cal_score(embeddings[0][0], embeddings[2][0])\n",
    "\n",
    "    print(score01, score02)\n",
    "\n",
    "def cal_score(a, b):\n",
    "    '''\n",
    "    코사인 유사도 구하는 함수\n",
    "    '''\n",
    "    if len(a.shape) == 1: a = a.unsqueeze(0)\n",
    "    if len(b.shape) == 1: b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = a / a.norm(dim=1)[:, None]\n",
    "    b_norm = b / b.norm(dim=1)[:, None]\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c79c6e8-ae72-4193-8c3a-d58a1102f17f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[92.7287]], grad_fn=<MulBackward0>) tensor([[79.8030]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sentences1 = ['이번 주 일요일에 분당 이마트 점은 문을 여나요',\n",
    "             '일요일에 분당 이마트는 문 열어요?',\n",
    "             '분당 이마트 점은 토요일에 몇 시까지 하나요']\n",
    "\n",
    "show_embedding_score(tokenizer, model, sentences1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07951b39-86bc-48bc-9815-9bdedc939148",
   "metadata": {},
   "source": [
    "## 세이지 메이커로 모델 배포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8a29ba0-5fc0-4602-8f2f-5e3e91f95c99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::677146750822:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547f4389-322f-489a-8635-16fd6ce06efc",
   "metadata": {},
   "source": [
    "## HF Model ID, HF_TASK 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf56771f-e5f7-4eea-92ff-e66402298e60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "  'HF_MODEL_ID':'BM-K/KoSimCSE-roberta', # model_id from hf.co/models\n",
    "  'HF_TASK':'feature-extraction'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   env=hub,\n",
    "   role=role, # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.26\", # transformers version used\n",
    "   pytorch_version=\"1.13\", # pytorch version used\n",
    "   py_version=\"py39\", # python version of the DLC\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c9b58-d0d5-4355-bd19-fae6d38676d1",
   "metadata": {},
   "source": [
    "## 모델 배포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82a23af0-8cdf-46c0-af57-0aa6c6276001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "time_stamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "endpoint_name = f\"KoSimCSE-roberta-\" + time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef219c36-51fa-4ff8-8e0c-c357e34a3cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!CPU times: user 164 ms, sys: 10.9 ms, total: 175 ms\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   endpoint_name = endpoint_name,\n",
    "   instance_type=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf10b7c9-e0e0-4f50-a8db-2d4a097e0bb4",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7236b209-867d-439a-8ae0-f954122912f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences2 = ['분당 이마트점에 KT 대리점이 있나요?',\n",
    "             '거기 이마트점에 KT 대리점이 있나요?',\n",
    "             '분당 아미트 점은 지하 주차장이 있나요?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "440b5df4-710b-4f7d-a5c4-6548f477df92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "payload_1 = {\n",
    "    \"inputs\" : sentences1\n",
    "}\n",
    "\n",
    "payload_2 = {\n",
    "    \"inputs\" : sentences2\n",
    "}\n",
    "\n",
    "def predict_payload(data):\n",
    "    res = predictor.predict(data=data)\n",
    "    res = np.array(res) # .squeeze().squeeze()\n",
    "    # print(\"res: \", res.shape)\n",
    "    # print(\"embedding dimension: \", len(res[0][0][0]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182c0535-0472-45fb-86aa-f99d23e4f87a",
   "metadata": {},
   "source": [
    "## Sample Test (한개의 문장 임베딩 보여 주기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df1c1c18-755e-4388-8271-345ec670405c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payload_0 : \n",
      " {'inputs': '이번 주 일요일에 분당 이마트 점은 문을 여나요'}\n",
      "embeding size:  768\n",
      "embeding content from 0 to 10 out of 768:  [-0.2569178  -0.19823857  0.89699048 -1.70428038 -0.11973442  0.28725004\n",
      "  0.39328021 -0.48056296 -0.17160198 -0.66424179]\n"
     ]
    }
   ],
   "source": [
    "payload_0 = {\n",
    "    \"inputs\" : \"이번 주 일요일에 분당 이마트 점은 문을 여나요\"\n",
    "}\n",
    "\n",
    "\n",
    "response = predict_payload(payload_0)\n",
    "emb_len = len(response[0][0])\n",
    "print(\"payload_0 : \\n\", payload_0)\n",
    "print(\"embeding size: \", emb_len)\n",
    "print(f\"embeding content from 0 to 10 out of {emb_len}: \", response[0][0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "493da749-9d9b-4c68-8881-dcc9fd32fd5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_embedding_score2(payload):\n",
    "    '''\n",
    "    # res \n",
    "    # 1st dim: samples, 2nd dim: place_hoder, 3rd_dim : CLS, ohter tokens \n",
    "    # res.shape --> (3,1)\n",
    "    # len(res[1][0]) --> 11 두번째 샘플의 11개 토큰\n",
    "    # len(res[1][0][0]) --> 두번째 샘플의 , 첫번째 토큰 임베딩 (764 사이즈)\n",
    "    '''\n",
    "    res = predict_payload(payload)    \n",
    "    embeddings_0 = torch.Tensor(res[0][0][0]) \n",
    "    embeddings_1 = torch.Tensor(res[1][0][0])\n",
    "    embeddings_2 = torch.Tensor(res[2][0][0])\n",
    "\n",
    "    score01 = cal_score(embeddings_0, embeddings_1)\n",
    "    score02 = cal_score(embeddings_0, embeddings_2)    \n",
    "    print(score01, score02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "489046f9-c533-4757-9322-0d8f5481db00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payload_1: \n",
      " {'inputs': ['이번 주 일요일에 분당 이마트 점은 문을 여나요', '일요일에 분당 이마트는 문 열어요?', '분당 이마트 점은 토요일에 몇 시까지 하나요']}\n",
      "tensor([[92.7287]]) tensor([[79.8030]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14586/3087720064.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  res = np.array(res) # .squeeze().squeeze()\n"
     ]
    }
   ],
   "source": [
    "print(\"payload_1: \\n\", payload_1)\n",
    "show_embedding_score2(payload_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e0c8a28-22f0-449a-b89a-af3e3e9c2650",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payload_2: \n",
      " {'inputs': ['분당 이마트점에 KT 대리점이 있나요?', '거기 이마트점에 KT 대리점이 있나요?', '분당 아미트 점은 지하 주차장이 있나요?']}\n",
      "tensor([[89.2611]]) tensor([[53.1729]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14586/3087720064.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  res = np.array(res) # .squeeze().squeeze()\n"
     ]
    }
   ],
   "source": [
    "print(\"payload_2: \\n\", payload_2)\n",
    "show_embedding_score2(payload_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c37874-05e0-4365-b589-85eac896c906",
   "metadata": {},
   "source": [
    "## Boto3 invoke_endpoint() 사용하여 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57e0caff-fb69-4285-aa15-6ac801244d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64e6f979-ebd7-461a-aa98-6348ae9535fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def query_endpoint_embedding_with_json_payload(encoded_json, endpoint_name, content_type=\"application/json\"):\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=content_type, Body=encoded_json\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def transform_output(output: bytes) -> str:\n",
    "    response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "    # return response_json\n",
    "    return response_json[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d24e98b6-0092-4edf-943b-d1f94a960db3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KoSimCSE-roberta-2024-02-13-00-16-45'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d37d04c5-e6df-4520-8bcc-f013ab414732",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫문장 임베딩 사이즈:  768\n",
      "두번째 문장 임베딩 사이즈:  768\n"
     ]
    }
   ],
   "source": [
    "sentences2_1 = \"분당 이마트점에 KT 대리점이 있나요?\"\n",
    "sentences2_2 = \"거기 이마트점에 KT 대리점이 있나요?\"\n",
    "\n",
    "payload_2_1 = {\n",
    "    \"inputs\" : sentences2_1\n",
    "}\n",
    "\n",
    "payload_2_2 = {\n",
    "    \"inputs\" : sentences2_2\n",
    "}\n",
    "\n",
    "# 첫번째 문장\n",
    "query_response = query_endpoint_embedding_with_json_payload(\n",
    "    json.dumps(payload_2_1).encode(\"utf-8\"), endpoint_name=endpoint_name\n",
    ")\n",
    "\n",
    "emb_1 = transform_output(query_response['Body'])\n",
    "print(\"첫문장 임베딩 사이즈: \", len(emb_1))\n",
    "\n",
    "# 두번째 문장\n",
    "query_response = query_endpoint_embedding_with_json_payload(\n",
    "    json.dumps(payload_2_2).encode(\"utf-8\"), endpoint_name=endpoint_name\n",
    ")\n",
    " \n",
    "emb_2 = transform_output(query_response['Body'])\n",
    "print(\"두번째 문장 임베딩 사이즈: \", len(emb_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7bd2977-e376-47f6-8f19-0e786acc4d04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[89.2611]])\n"
     ]
    }
   ],
   "source": [
    "def show_embedding_score3(emb1, emb2):\n",
    "\n",
    "    embeddings_0 = torch.Tensor(emb1) \n",
    "    embeddings_1 = torch.Tensor(emb2)\n",
    "\n",
    "    score01 = cal_score(embeddings_0, embeddings_1)\n",
    "\n",
    "    print(score01)\n",
    "\n",
    "show_embedding_score3(emb_1, emb_2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a849eda9-2cb4-4f2c-a5b1-92ea5c65080d",
   "metadata": {},
   "source": [
    "## 엔드포인트 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5705454b-3424-4766-8429-e6cc9712569a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # delete endpoint\n",
    "# predictor.delete_model()\n",
    "# predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ff19357-f60e-4ee4-81ab-2fa5b3761410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store  endpoint_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
